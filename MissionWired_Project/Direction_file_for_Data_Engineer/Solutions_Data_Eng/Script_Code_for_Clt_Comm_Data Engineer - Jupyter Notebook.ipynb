{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae53dd7",
   "metadata": {},
   "source": [
    "#                                                    Exercises\n",
    "       1. Produce a “people” file with the following schema. Save it as a CSV with a header line to the working directory.\n",
    "\n",
    "       2. Use the output of #1 to produce an “acquisition_facts” file with the following schema that aggregates stats                                    about when people in the dataset were acquired. Save it to the working directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5a2d7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Data\n",
    "### A dataset simulating CRM data is available in some public AWS S3 files:\n",
    "#### ●\tConstituent Information: https://als-hiring.s3.amazonaws.com/fake_data/2020-07-01_17%3A11%3A00/cons.csv\n",
    "#### ●\tConstituent Email Addresses: https://als-hiring.s3.amazonaws.com/fake_data/2020-07-01_17%3A11%3A00/cons_email.csv\n",
    "     ○  Boolean columns (including is_primary) in all of these datasets are 1/0 numeric values. 1 means True, 0 means False.\n",
    "#### ●\tConstituent Subscription Status: https://als-hiring.s3.amazonaws.com/fake_data/2020-0701_17%3A11%3A00/cons_email_chapter_subscription.csv\n",
    "       ○\tWe only care about subscription statuses where chapter_id is 1.\n",
    "       ○\tIf an email is not present in this table, it is assumed to still be subscribed where chapter_id is 1.\n",
    "        \t 'the script is wrote without consideration of memory'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e53bcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install queries\\n!pip install sql-query\\n!pip install ipython-sql\\n!pip install --upgrade ipython\\n!pip install duckdb\\n!pip install pandasql\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to install this package if not in the machine for this just uncoment it and run\n",
    "'''\n",
    "!pip install queries\n",
    "!pip install sql-query\n",
    "!pip install ipython-sql\n",
    "!pip install --upgrade ipython\n",
    "!pip install duckdb\n",
    "!pip install pandasql\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d41ddab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import required Libraries...\n",
      "done import required Libraries\n"
     ]
    }
   ],
   "source": [
    "#Import required Libraries\n",
    "print(\"Import required Libraries...\")\n",
    "import pandas as pd\n",
    "import requests, os\n",
    "import pandasql as ps\n",
    "import duckdb\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "print(\"done import required Libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e641b709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import required dataframe...\n",
      "Done import required dataframe\n"
     ]
    }
   ],
   "source": [
    "# Get data file from downloaded path\n",
    "print(\"Import required dataframe...\")\n",
    "cons_csv = pd.read_csv(\"https://als-hiring.s3.amazonaws.com/fake_data/2020-07-01_17%3A11%3A00/cons.csv\") \n",
    "cons_email_csv = pd.read_csv(\"https://als-hiring.s3.amazonaws.com/fake_data/2020-07-01_17%3A11%3A00/cons_email.csv\") \n",
    "cons_email_chp_csv = pd.read_csv(\"https://als-hiring.s3.amazonaws.com/fake_data/2020-07-01_17%3A11%3A00/cons_email_chapter_subscription.csv\") \n",
    "print(\"Done import required dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee9463",
   "metadata": {},
   "source": [
    "### check the shape of the Data Recall the number of Row and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d02f36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cons.csv  Row is   700000   and the number of Columns is   29\n",
      "\n",
      "the cons_email.csv  Row is   1400000   and the number of Columns is   16\n",
      "\n",
      "the cons_email_chapter_subscription.csv  Row is   350000   and the number of Columns is   6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"the cons.csv  Row is   {cons_csv.shape[0]}   and the number of Columns is   {len(cons_csv.columns)}\")\n",
    "print()\n",
    "print(f\"the cons_email.csv  Row is   {cons_email_csv.shape[0]}   and the number of Columns is   {len(cons_email_csv.columns)}\")\n",
    "print()\n",
    "print(f\"the cons_email_chapter_subscription.csv  Row is   {cons_email_chp_csv.shape[0]}   and the number of Columns is   {len(cons_email_chp_csv.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6fbc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700000 entries, 0 to 699999\n",
      "Data columns (total 29 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   cons_id                     700000 non-null  int64  \n",
      " 1   prefix                      350304 non-null  object \n",
      " 2   firstname                   350244 non-null  object \n",
      " 3   middlename                  560213 non-null  object \n",
      " 4   lastname                    349314 non-null  object \n",
      " 5   suffix                      349541 non-null  object \n",
      " 6   salutation                  350021 non-null  object \n",
      " 7   gender                      349891 non-null  object \n",
      " 8   birth_dt                    349954 non-null  object \n",
      " 9   title                       350082 non-null  object \n",
      " 10  employer                    349228 non-null  object \n",
      " 11  occupation                  350239 non-null  object \n",
      " 12  income                      350637 non-null  float64\n",
      " 13  source                      350026 non-null  object \n",
      " 14  subsource                   350315 non-null  object \n",
      " 15  userid                      700000 non-null  int64  \n",
      " 16  password                    700000 non-null  object \n",
      " 17  is_validated                700000 non-null  int64  \n",
      " 18  is_banned                   700000 non-null  int64  \n",
      " 19  change_password_next_login  700000 non-null  int64  \n",
      " 20  consent_type_id             700000 non-null  int64  \n",
      " 21  create_dt                   700000 non-null  object \n",
      " 22  create_app                  700000 non-null  int64  \n",
      " 23  create_user                 700000 non-null  int64  \n",
      " 24  modified_dt                 700000 non-null  object \n",
      " 25  modified_app                700000 non-null  int64  \n",
      " 26  modified_user               700000 non-null  int64  \n",
      " 27  status                      700000 non-null  int64  \n",
      " 28  note                        69884 non-null   object \n",
      "dtypes: float64(1), int64(11), object(17)\n",
      "memory usage: 154.9+ MB\n"
     ]
    }
   ],
   "source": [
    "cons_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc912697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1400000 entries, 0 to 1399999\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count    Dtype \n",
      "---  ------                --------------    ----- \n",
      " 0   cons_email_id         1400000 non-null  int64 \n",
      " 1   cons_id               1400000 non-null  int64 \n",
      " 2   cons_email_type_id    1400000 non-null  int64 \n",
      " 3   is_primary            1400000 non-null  int64 \n",
      " 4   email                 1400000 non-null  object\n",
      " 5   canonical_local_part  700029 non-null   object\n",
      " 6   domain                1400000 non-null  object\n",
      " 7   double_validation     699825 non-null   object\n",
      " 8   create_dt             1400000 non-null  object\n",
      " 9   create_app            1400000 non-null  int64 \n",
      " 10  create_user           1400000 non-null  int64 \n",
      " 11  modified_dt           1400000 non-null  object\n",
      " 12  modified_app          1400000 non-null  int64 \n",
      " 13  modified_user         1400000 non-null  int64 \n",
      " 14  status                1400000 non-null  int64 \n",
      " 15  note                  139535 non-null   object\n",
      "dtypes: int64(9), object(7)\n",
      "memory usage: 170.9+ MB\n"
     ]
    }
   ],
   "source": [
    "cons_email_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0eeb3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 350000 entries, 0 to 349999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                              Non-Null Count   Dtype \n",
      "---  ------                              --------------   ----- \n",
      " 0   cons_email_chapter_subscription_id  350000 non-null  int64 \n",
      " 1   cons_email_id                       350000 non-null  int64 \n",
      " 2   chapter_id                          350000 non-null  int64 \n",
      " 3   isunsub                             350000 non-null  int64 \n",
      " 4   unsub_dt                            350000 non-null  object\n",
      " 5   modified_dt                         350000 non-null  object\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 16.0+ MB\n"
     ]
    }
   ],
   "source": [
    "cons_email_chp_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad1d7e",
   "metadata": {},
   "source": [
    "### recall the first 2 lines of each Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54bccfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table from Dataframe cons.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cons_id</th>\n",
       "      <th>prefix</th>\n",
       "      <th>firstname</th>\n",
       "      <th>middlename</th>\n",
       "      <th>lastname</th>\n",
       "      <th>suffix</th>\n",
       "      <th>salutation</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_dt</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>change_password_next_login</th>\n",
       "      <th>consent_type_id</th>\n",
       "      <th>create_dt</th>\n",
       "      <th>create_app</th>\n",
       "      <th>create_user</th>\n",
       "      <th>modified_dt</th>\n",
       "      <th>modified_app</th>\n",
       "      <th>modified_user</th>\n",
       "      <th>status</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vSkSIzEQJdXnqeTTTXSG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5958</td>\n",
       "      <td>Fri, 1983-08-26 06:02:03</td>\n",
       "      <td>1484</td>\n",
       "      <td>6162</td>\n",
       "      <td>Sun, 2015-12-27 09:28:02</td>\n",
       "      <td>4022</td>\n",
       "      <td>6349</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>II</td>\n",
       "      <td>boFqBKgLlSgEZsFrgCZd</td>\n",
       "      <td>E</td>\n",
       "      <td>Mon, 2004-11-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4236</td>\n",
       "      <td>Mon, 1979-03-05 21:08:54</td>\n",
       "      <td>4176</td>\n",
       "      <td>5476</td>\n",
       "      <td>Tue, 1989-06-20 13:28:57</td>\n",
       "      <td>9010</td>\n",
       "      <td>5698</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cons_id prefix firstname middlename lastname suffix            salutation  \\\n",
       "0        1    NaN       NaN        Lee      NaN     MD                   NaN   \n",
       "1        2    NaN       NaN        NaN      NaN     II  boFqBKgLlSgEZsFrgCZd   \n",
       "\n",
       "  gender         birth_dt                 title  ...  \\\n",
       "0      E              NaN  vSkSIzEQJdXnqeTTTXSG  ...   \n",
       "1      E  Mon, 2004-11-15                   NaN  ...   \n",
       "\n",
       "  change_password_next_login consent_type_id                 create_dt  \\\n",
       "0                          0            5958  Fri, 1983-08-26 06:02:03   \n",
       "1                          1            4236  Mon, 1979-03-05 21:08:54   \n",
       "\n",
       "  create_app create_user               modified_dt modified_app  \\\n",
       "0       1484        6162  Sun, 2015-12-27 09:28:02         4022   \n",
       "1       4176        5476  Tue, 1989-06-20 13:28:57         9010   \n",
       "\n",
       "   modified_user  status  note  \n",
       "0           6349       1   NaN  \n",
       "1           5698       1   NaN  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_csv = cons_csv.sort_values(by=['cons_id'], ascending=True)\n",
    "print(\"table from Dataframe cons.csv\")\n",
    "print()\n",
    "cons_csv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a0f661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table from Dataframe cons_email.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cons_email_id</th>\n",
       "      <th>cons_id</th>\n",
       "      <th>cons_email_type_id</th>\n",
       "      <th>is_primary</th>\n",
       "      <th>email</th>\n",
       "      <th>canonical_local_part</th>\n",
       "      <th>domain</th>\n",
       "      <th>double_validation</th>\n",
       "      <th>create_dt</th>\n",
       "      <th>create_app</th>\n",
       "      <th>create_user</th>\n",
       "      <th>modified_dt</th>\n",
       "      <th>modified_app</th>\n",
       "      <th>modified_user</th>\n",
       "      <th>status</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>548198</td>\n",
       "      <td>3361</td>\n",
       "      <td>1</td>\n",
       "      <td>xmartinez@vincent.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wed, 1994-01-26 23:49:16</td>\n",
       "      <td>4072</td>\n",
       "      <td>9954</td>\n",
       "      <td>Sat, 2014-04-19 19:10:39</td>\n",
       "      <td>1990</td>\n",
       "      <td>7595</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>491137</td>\n",
       "      <td>2474</td>\n",
       "      <td>1</td>\n",
       "      <td>hmiller@haynes.biz</td>\n",
       "      <td>jqCyozTDojYuylQPTHfm</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thu, 1999-12-09 06:18:27</td>\n",
       "      <td>1600</td>\n",
       "      <td>5716</td>\n",
       "      <td>Sat, 1984-07-14 05:55:27</td>\n",
       "      <td>4686</td>\n",
       "      <td>3248</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cons_email_id  cons_id  cons_email_type_id  is_primary  \\\n",
       "0              1   548198                3361           1   \n",
       "1              2   491137                2474           1   \n",
       "\n",
       "                   email  canonical_local_part       domain double_validation  \\\n",
       "0  xmartinez@vincent.com                   NaN    gmail.com               NaN   \n",
       "1     hmiller@haynes.biz  jqCyozTDojYuylQPTHfm  hotmail.com               NaN   \n",
       "\n",
       "                  create_dt  create_app  create_user  \\\n",
       "0  Wed, 1994-01-26 23:49:16        4072         9954   \n",
       "1  Thu, 1999-12-09 06:18:27        1600         5716   \n",
       "\n",
       "                modified_dt  modified_app  modified_user  status note  \n",
       "0  Sat, 2014-04-19 19:10:39          1990           7595       1  NaN  \n",
       "1  Sat, 1984-07-14 05:55:27          4686           3248       1  NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cons_email_csv = cons_email_csv.sort_values(by=['cons_email_id'], ascending=True)\n",
    "print(\"table from Dataframe cons_email.csv\")\n",
    "print()\n",
    "cons_email_csv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7bee1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table from Dataframe cons_email_chapter_subscription.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cons_email_chapter_subscription_id</th>\n",
       "      <th>cons_email_id</th>\n",
       "      <th>chapter_id</th>\n",
       "      <th>isunsub</th>\n",
       "      <th>unsub_dt</th>\n",
       "      <th>modified_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108533</th>\n",
       "      <td>108534</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon, 1973-08-20 02:16:04</td>\n",
       "      <td>Sun, 1977-10-02 12:32:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296065</th>\n",
       "      <td>296066</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue, 1974-07-09 06:29:34</td>\n",
       "      <td>Wed, 2003-05-28 02:47:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cons_email_chapter_subscription_id  cons_email_id  chapter_id  \\\n",
       "108533                              108534              3           1   \n",
       "296065                              296066              4           1   \n",
       "\n",
       "        isunsub                  unsub_dt               modified_dt  \n",
       "108533        1  Mon, 1973-08-20 02:16:04  Sun, 1977-10-02 12:32:10  \n",
       "296065        1  Tue, 1974-07-09 06:29:34  Wed, 2003-05-28 02:47:44  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_email_chp_csv = cons_email_chp_csv.sort_values(by=['cons_email_id'], ascending=True)\n",
    "print(\"table from Dataframe cons_email_chapter_subscription.csv\")\n",
    "print()\n",
    "cons_email_chp_csv.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d5a61",
   "metadata": {},
   "source": [
    "### Join the Dataframe from cons.csv with cons_email.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7954b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cons.csv + cons_email.csv  row nbr is   1494361   and the number of columns is   44 \n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(cons_csv , cons_email_csv ,left_on=\"cons_id\", right_on=\"cons_id\", how=\"left\",suffixes=('_csv1', '_csv2'))\n",
    "print(f\"the cons.csv + cons_email.csv  row nbr is   {df.shape[0]}   and the number of columns is   {len(df.columns)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a25f62ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cons.csv + cons_email.csv + cons_email_chp_csv row nbr is   1568877   and the number of columns is   49 \n"
     ]
    }
   ],
   "source": [
    "df2 = pd.merge(df , cons_email_chp_csv ,left_on=\"cons_email_id\", right_on=\"cons_email_id\", how=\"outer\",suffixes=('_df', '_csv3'))\n",
    "print(f\"the cons.csv + cons_email.csv + cons_email_chp_csv row nbr is   {df2.shape[0]}   and the number of columns is   {len(df2.columns)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90fa6a",
   "metadata": {},
   "source": [
    "### query the DataFrame  cons.csv + cons_email.csv + cons_email_chp_csv according to this filter     \n",
    "      ○    We only care about subscription statuses where chapter_id is 1.\n",
    "      ○    If an email is not present in this table, it is assumed to still be subscribed where chapter_id is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86694d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the engine from duckdb\n",
    "def dbrun(query: str) -> pd.DataFrame:\n",
    "    result = dbcon.query(query).to_df()\n",
    "    return result\n",
    "#connect to engine\n",
    "dbcon = duckdb.connect()\n",
    "#run the query and save data as df3\n",
    "df3 = dbrun('''SELECT * FROM df2 WHERE email IS NULL OR email = '' OR chapter_id = 1 ''')\n",
    "\n",
    "'''\n",
    "#without usesing the step to join or merge the table first we can run the query to produce the df3 data from this query\n",
    "df3 = dbrun(\"\"\"SELECT *FROM cons_csv a LEFT JOIN cons_email_csv b ON a.cons_id = b.cons_id LEFT JOIN cons_email_chp_csv c ON b.cons_email_id = c.cons_email_id WHERE (c.chapter_id = 1  OR b.email IS NULL)\"\"\")\n",
    "'''\n",
    "# Filter the Data on \"email\" ,\"source\", \"isunsub\" , \"create_dt_csv2\", \"modified_dt\"\n",
    "Table_exercise1 = df3[[\"email\" ,\"source\", \"isunsub\" , \"is_primary\" , \"create_dt_csv2\", \"modified_dt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a8e0b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  there is duplicate on email column and the Dataframe\n",
      "\n",
      "\n",
      "this is the statistique of missing value in the data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of missing value</th>\n",
       "      <th>percentage(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>email</th>\n",
       "      <td>94361</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>184493</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isunsub</th>\n",
       "      <td>94361</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_primary</th>\n",
       "      <td>94361</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>create_dt_csv2</th>\n",
       "      <td>94361</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modified_dt</th>\n",
       "      <td>94361</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                number of missing value  percentage(%)\n",
       "email                             94361            6.0\n",
       "source                           184493           12.0\n",
       "isunsub                           94361            6.0\n",
       "is_primary                        94361            6.0\n",
       "create_dt_csv2                    94361            6.0\n",
       "modified_dt                       94361            6.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicate on column email\n",
    "boolea = Table_exercise1[\"email\"].duplicated().any() # True\n",
    "print(f\"{boolea}  there is duplicate on email column and the Dataframe\")\n",
    "\n",
    "# cheack missing value\n",
    "print()\n",
    "print()\n",
    "print(\"this is the statistique of missing value in the data\")\n",
    "print()\n",
    "percentage_missing_each_col = pd.DataFrame(Table_exercise1.isnull().sum())\n",
    "percentage_missing_each_col.rename(columns = {0:\"number of missing value\"}, inplace = True)\n",
    "\n",
    "percentage_missing_each_col[\"percentage(%)\"] = (percentage_missing_each_col[\"number of missing value\"]/df.shape[0]*100).round(0)\n",
    "\n",
    "percentage_missing_each_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc9910",
   "metadata": {},
   "source": [
    "### Treat the missing value on the source column here we will use sklearn imputer on most frequent to replace the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e52caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "this is the statistique of missing value in the data with treated source column\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of missing value</th>\n",
       "      <th>percentage(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>email</th>\n",
       "      <td>94361</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isunsub</th>\n",
       "      <td>94361</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_primary</th>\n",
       "      <td>94361</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>create_dt_csv2</th>\n",
       "      <td>94361</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modified_dt</th>\n",
       "      <td>94361</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                number of missing value  percentage(%)\n",
       "email                             94361            6.0\n",
       "source                                0            0.0\n",
       "isunsub                           94361            6.0\n",
       "is_primary                        94361            6.0\n",
       "create_dt_csv2                    94361            6.0\n",
       "modified_dt                       94361            6.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let call the sklean imputer on  most frequent \n",
    "the_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# select the column to impute\n",
    "#column_to_impute = 'source'\n",
    "\n",
    "# now let impute missing values in selected column source\n",
    "imputed_column = the_imputer.fit_transform(Table_exercise1[['source']])\n",
    "\n",
    "# use the value and replace the original column \n",
    "Table_exercise1 = Table_exercise1.assign(source=lambda d: pd.DataFrame(imputed_column))\n",
    "\n",
    "#print the statistic of missing value and recall that the source column is now 0%\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"this is the statistique of missing value in the data with treated source column\")\n",
    "print()\n",
    "percentage_missing_each_col2 = pd.DataFrame(Table_exercise1.isnull().sum())\n",
    "percentage_missing_each_col2.rename(columns = {0:\"number of missing value\"}, inplace = True)\n",
    "\n",
    "percentage_missing_each_col2[\"percentage(%)\"] = (percentage_missing_each_col2[\"number of missing value\"]/df.shape[0]*100).round(0)\n",
    "\n",
    "percentage_missing_each_col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef6e71fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  there is duplicate on email column and the Dataframe and we will take them out treament...\n",
      "\n",
      "Now there is no duplicate on email and the other duplicate are reasonable,we procede to treat duplicate on email only\n"
     ]
    }
   ],
   "source": [
    "# check duplicate again on column email\n",
    "boole = Table_exercise1[\"email\"].duplicated().any() # True\n",
    "print(f\"{boole}  there is duplicate on email column and the Dataframe and we will take them out treament...\")\n",
    "\n",
    "#since the duplicate here are not impacting our analysis, we will not remove it in other column \n",
    "#Table_exercise1.drop_duplicates(subset=\"email\", keep=\"last\") \n",
    "\n",
    "# From the Dataframe select all column  except the column where email is missing an\n",
    "Table_exercise1 = Table_exercise1[Table_exercise1['email'].notna()]\n",
    "\n",
    "print()\n",
    "print(\"Now there is no duplicate on email and the other duplicate are reasonable,we procede to treat duplicate on email only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6fd6031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the 0 and 1 in the table to False and True boolean\n",
    "for i in range(len(Table_exercise1.columns)):\n",
    "    if set(Table_exercise1.iloc[:,i].unique()) == set([0,1]): \n",
    "        Table_exercise1.iloc[:,i]= Table_exercise1.iloc[:,i].replace([1,0],['TRUE','FALSE'])\n",
    "\n",
    "# Rename column with proper name\n",
    "Table_exercise1.rename(columns = {\"source\":\"code\", \"isunsub\":\"is_unsub\", \"create_dt_csv2\":\"created_dt\",\n",
    "                                  \"modified_dt\":\"updated_dt\"}, inplace = True)\n",
    "\n",
    "#filter the table and name it Email_table\n",
    "Email_table = Table_exercise1[[\"email\" ,\"code\", \"is_unsub\" , \"created_dt\", \"updated_dt\"]].copy()\n",
    "\n",
    "# Set value on the Dataframe to proper type\n",
    "Email_table.loc[ : , \"email\"] = Email_table[\"email\"].convert_dtypes(convert_string=True)\n",
    "Email_table.loc[ : , \"code\"]  = Email_table[\"code\"].convert_dtypes(convert_string=True)\n",
    "Email_table.loc[ : , \"is_unsub\"] = Email_table[\"is_unsub\"].convert_dtypes(convert_boolean=True)\n",
    "Email_table.is_unsub = Email_table.is_unsub.astype('bool')\n",
    "Email_table.loc[ : , \"created_dt\"] = pd.to_datetime(Email_table[\"created_dt\"])\n",
    "Email_table.loc[ : , \"updated_dt\"] = pd.to_datetime(Email_table[\"updated_dt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d5fc811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a funtion to create folder in the working directory the name of the folder will be folow by the dataetime of creation\n",
    "\n",
    "# Folder 1\n",
    "def create_folder(FolderName):\n",
    "    date = datetime.now()\n",
    "    now = date.strftime(\"%Y-%m-%d %H-%M\")\n",
    "    print (f'creating folder {FolderName}....')\n",
    "    print (f'this table will be in {FolderName} that is in Email_table folder')\n",
    "    newpath0 = os.path.join(os.getcwd(),FolderName+now) \n",
    "    if not os.path.exists(newpath0):\n",
    "        os.makedirs(newpath0)\n",
    "    Path0 = newpath0.rstrip('\\n')\n",
    "    filenameCreated0 = Path0\n",
    "    return filenameCreated0\n",
    "\n",
    "# Folder 2\n",
    "def create_folder2(FolderName):\n",
    "    date = datetime.now()\n",
    "    now = date.strftime(\"%Y-%m-%d %H-%M\")\n",
    "    print (f'creating folder {FolderName}....')\n",
    "    print (f'this table will be in {FolderName} that is in Date_table_aggregate folder')\n",
    "    newpath0 = os.path.join(os.getcwd(),FolderName+now) \n",
    "    if not os.path.exists(newpath0):\n",
    "        os.makedirs(newpath0)\n",
    "    Path0 = newpath0.rstrip('\\n')\n",
    "    filenameCreated0 = Path0\n",
    "    return filenameCreated0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0583aa",
   "metadata": {},
   "source": [
    "### Save the Dataframe Email_table in the folder in working directory this is the table for ETL excercie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3849991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the recall of all Dataframe column type data from Email_table.csv\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 275484 entries, 0 to 369844\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   email       275484 non-null  string        \n",
      " 1   code        275484 non-null  string        \n",
      " 2   is_unsub    275484 non-null  bool          \n",
      " 3   created_dt  275484 non-null  datetime64[ns]\n",
      " 4   updated_dt  275484 non-null  datetime64[ns]\n",
      "dtypes: bool(1), datetime64[ns](2), string(2)\n",
      "memory usage: 10.8 MB\n",
      "\n",
      "\n",
      "creating folder ETL_exercise_1_....\n",
      "this table will be in ETL_exercise_1_ that is in Email_table folder\n",
      "creating folder ETL_exercise_1_....\n",
      "this table will be in ETL_exercise_1_ that is in Email_table folder\n",
      "\n",
      "\n",
      "This is the recall of first 6 row and columns of Email_table.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>code</th>\n",
       "      <th>is_unsub</th>\n",
       "      <th>created_dt</th>\n",
       "      <th>updated_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caustin@spears-carson.com</td>\n",
       "      <td>facebook</td>\n",
       "      <td>True</td>\n",
       "      <td>1987-01-23 13:51:26</td>\n",
       "      <td>1988-12-19 12:14:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deborah57@shaffer-reed.org</td>\n",
       "      <td>facebook</td>\n",
       "      <td>True</td>\n",
       "      <td>1995-02-03 05:29:21</td>\n",
       "      <td>2009-12-10 06:34:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>klewis@ford.biz</td>\n",
       "      <td>organic</td>\n",
       "      <td>True</td>\n",
       "      <td>2013-05-02 09:20:11</td>\n",
       "      <td>1985-07-16 03:09:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94364</th>\n",
       "      <td>stephenhamilton@gmail.com</td>\n",
       "      <td>organic</td>\n",
       "      <td>True</td>\n",
       "      <td>1976-05-23 12:23:38</td>\n",
       "      <td>1991-03-17 04:25:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94365</th>\n",
       "      <td>inovak@barnett-wise.com</td>\n",
       "      <td>organic</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-01-11 14:35:11</td>\n",
       "      <td>1978-11-05 23:14:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94366</th>\n",
       "      <td>norr@donovan.com</td>\n",
       "      <td>twitter</td>\n",
       "      <td>True</td>\n",
       "      <td>1973-06-22 22:47:25</td>\n",
       "      <td>2011-02-08 12:49:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            email      code  is_unsub          created_dt  \\\n",
       "0       caustin@spears-carson.com  facebook      True 1987-01-23 13:51:26   \n",
       "1      deborah57@shaffer-reed.org  facebook      True 1995-02-03 05:29:21   \n",
       "2                 klewis@ford.biz   organic      True 2013-05-02 09:20:11   \n",
       "94364   stephenhamilton@gmail.com   organic      True 1976-05-23 12:23:38   \n",
       "94365     inovak@barnett-wise.com   organic      True 2004-01-11 14:35:11   \n",
       "94366            norr@donovan.com   twitter      True 1973-06-22 22:47:25   \n",
       "\n",
       "               updated_dt  \n",
       "0     1988-12-19 12:14:02  \n",
       "1     2009-12-10 06:34:18  \n",
       "2     1985-07-16 03:09:10  \n",
       "94364 1991-03-17 04:25:12  \n",
       "94365 1978-11-05 23:14:09  \n",
       "94366 2011-02-08 12:49:10  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"This is the recall of all Dataframe column type data from Email_table.csv\")\n",
    "print()\n",
    "Email_table.info()\n",
    "print()\n",
    "print()\n",
    "# Create folder and file name\n",
    "FolderName1 = \"ETL_exercise_1_\"\n",
    "FileName1 = \"Email_table.csv\"\n",
    "# Create folder in working directory giving the defien funtion.\n",
    "create_folder(FolderName1)\n",
    "# Set the path of the file to save\n",
    "path123 = os.path.join(create_folder(FolderName1), FileName1) \n",
    "# Save the file \n",
    "Email_table.to_csv(path123)\n",
    "print()\n",
    "print()\n",
    "print(\"This is the recall of first 6 row and columns of Email_table.csv\")\n",
    "Email_table.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb36ec8b",
   "metadata": {},
   "source": [
    "### Save the Dataframe Date_table_aggregate in the folder in working directory. the table is for ETL excercie2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edb06c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the recall of all Dataframe column type data in Date_table_aggr.csv\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 275458 entries, 0 to 275457\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   acquisition_date  275458 non-null  datetime64[ns]\n",
      " 1   acquisitions      275458 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1)\n",
      "memory usage: 4.2 MB\n",
      "None\n",
      "\n",
      "\n",
      "creating folder ETL_exercise_2_....\n",
      "this table will be in ETL_exercise_2_ that is in Date_table_aggregate folder\n",
      "creating folder ETL_exercise_2_....\n",
      "this table will be in ETL_exercise_2_ that is in Email_table folder\n",
      "\n",
      "\n",
      "This is the recall of first 6 row and columns of Date_table_aggr.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acquisition_date</th>\n",
       "      <th>acquisitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-06-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-02-28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-11-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acquisition_date  acquisitions\n",
       "0       2018-09-25             2\n",
       "1       2012-12-29             2\n",
       "2       1970-06-22             2\n",
       "3       1998-02-28             2\n",
       "4       2015-03-03             2\n",
       "5       2012-11-01             2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Datafome for excercise 2 from ETL excercise\n",
    "Date_table_aggr = Email_table[[ \"created_dt\"]].copy()\n",
    "# Rename the column to acquisition_date\n",
    "Date_table_aggr.rename(columns = {\"created_dt\":\"acquisition_date\"}, inplace = True)\n",
    "# Create new column acquisitions that will show aggragate date count\n",
    "Date_table_aggr = Date_table_aggr.groupby(['acquisition_date']).size().reset_index(name='acquisitions')\n",
    "# Sort the value from the column acquisitions as descending\n",
    "Date_table_aggr = Date_table_aggr.sort_values(\"acquisitions\",axis=0,ascending=False,inplace=False,kind='quicksort',na_position='last',ignore_index=False)\n",
    "\n",
    "Date_table_aggr[ \"acquisition_date\"] = pd.to_datetime(Date_table_aggr[ \"acquisition_date\"]).dt.normalize()\n",
    "Date_table_aggr.reset_index(drop=True, inplace=True)\n",
    "print(\"This is the recall of all Dataframe column type data in Date_table_aggr.csv\")\n",
    "print()\n",
    "print(f\"{Date_table_aggr.info()}\")\n",
    "print()\n",
    "print()\n",
    "# Create folder and file name\n",
    "FolderName2 = \"ETL_exercise_2_\"\n",
    "FileName2 = \"Date_table_aggregate.csv\"\n",
    "# Create folder in working directory giving the defien funtion.\n",
    "create_folder2(FolderName2)\n",
    "# Set the path of the file to save\n",
    "path123 = os.path.join(create_folder(FolderName2), FileName2) \n",
    "# Save the file \n",
    "Email_table.to_csv(path123)\n",
    "print()\n",
    "print()\n",
    "print(\"This is the recall of first 6 row and columns of Date_table_aggr.csv\")\n",
    "Date_table_aggr.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac36373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
